{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Visualization Example\n",
    "\n",
    "Real-time visualization of MNIST training on a CNN, using TensorFlow and [TensorDebugger](https://github.com/ericjang/tdb)\n",
    "\n",
    "The visualizations in this notebook won't show up on http://nbviewer.ipython.org. To view the widgets and interact with them, you will need to download this notebook and run it with a Jupyter Notebook server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.utils.load_extensions('tdb_ext/main')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.utils.load_extensions('tdb_ext/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('/home/evjang/thesis/tensor_debugger')\n",
    "import tdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tdb.examples import mnist, viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_data_node,\n",
    "    train_labels_node,\n",
    "    validation_data_node,\n",
    "    test_data_node,\n",
    "    # predictions\n",
    "    train_prediction,\n",
    "    validation_prediction,\n",
    "    test_prediction,\n",
    "    # weights\n",
    "    conv1_weights,\n",
    "    conv2_weights,\n",
    "    fc1_weights,\n",
    "    fc2_weights,\n",
    "    # training\n",
    "    optimizer,\n",
    "    loss,\n",
    "    learning_rate,\n",
    "    summaries) = mnist.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach TDB Plot Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g=tf.get_default_graph()\n",
    "p0=tdb.plot_op(viz.viz_activations,inputs=[train_prediction])\n",
    "p1=tdb.plot_op(viz.viz_conv_weights,inputs=[g.as_graph_element(conv1_weights)])\n",
    "p2=tdb.plot_op(viz.viz_conv_weights,inputs=[g.as_graph_element(conv2_weights)])\n",
    "p3=tdb.plot_op(viz.viz_fc_weights,inputs=[g.as_graph_element(fc1_weights)])\n",
    "p4=tdb.plot_op(viz.viz_fc_weights,inputs=[g.as_graph_element(fc2_weights)])\n",
    "p2=tdb.plot_op(viz.viz_conv_hist,inputs=[g.as_graph_element(conv1_weights)])\n",
    "ploss=tdb.plot_op(viz.watch_loss,inputs=[loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug + Visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Extracting', '/contrib/projects/tensorflow/tensorflow/tensorflow/models/image/mnist/data/train-images-idx3-ubyte.gz')\n",
      "('Extracting', '/contrib/projects/tensorflow/tensorflow/tensorflow/models/image/mnist/data/train-labels-idx1-ubyte.gz')\n",
      "('Extracting', '/contrib/projects/tensorflow/tensorflow/tensorflow/models/image/mnist/data/t10k-images-idx3-ubyte.gz')\n",
      "('Extracting', '/contrib/projects/tensorflow/tensorflow/tensorflow/models/image/mnist/data/t10k-labels-idx1-ubyte.gz')\n"
     ]
    }
   ],
   "source": [
    "(train_data, \n",
    " train_labels, \n",
    " validation_data, \n",
    " validation_labels, \n",
    " test_data, \n",
    " test_labels) = mnist.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s=tf.InteractiveSession()\n",
    "tf.initialize_all_variables().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29.668428\n",
      "loss: 15.983353\n",
      "loss: 11.249242\n",
      "loss: 10.028939\n",
      "loss: 8.065391\n",
      "loss: 9.335689\n",
      "loss: 7.316875\n",
      "loss: 8.376289\n",
      "loss: 7.735221\n",
      "loss: 8.383675\n",
      "loss: 5.704120\n",
      "loss: 6.037778\n",
      "loss: 7.309663\n",
      "loss: 7.349874\n",
      "loss: 7.528041\n",
      "loss: 8.209503\n",
      "loss: 5.364178\n",
      "loss: 6.238027\n",
      "loss: 4.885421\n",
      "loss: 7.149874\n",
      "loss: 6.667716\n",
      "loss: 7.664586\n",
      "loss: 5.739111\n",
      "loss: 5.234925\n",
      "loss: 6.845879\n",
      "loss: 7.644434\n",
      "loss: 7.803726\n",
      "loss: 6.660363\n",
      "loss: 9.883630\n",
      "loss: 5.740071\n",
      "loss: 5.631568\n",
      "loss: 4.630940\n",
      "loss: 4.878671\n",
      "loss: 9.181991\n",
      "loss: 5.782062\n",
      "loss: 5.157544\n",
      "loss: 6.841264\n",
      "loss: 5.022801\n",
      "loss: 6.708258\n",
      "loss: 5.301538\n",
      "loss: 7.587475\n",
      "loss: 7.271310\n",
      "loss: 7.376766\n",
      "loss: 6.834531\n",
      "loss: 5.586595\n",
      "loss: 8.022355\n",
      "loss: 7.323628\n",
      "loss: 6.992519\n",
      "loss: 7.361020\n",
      "loss: 3.928694\n",
      "loss: 6.050151\n",
      "loss: 6.464612\n",
      "loss: 8.642132\n",
      "loss: 6.460655\n",
      "loss: 6.386369\n",
      "loss: 6.559804\n",
      "loss: 4.907454\n",
      "loss: 8.747141\n",
      "loss: 6.776401\n",
      "loss: 6.437348\n",
      "loss: 5.872069\n",
      "loss: 6.829823\n",
      "loss: 6.220968\n",
      "loss: 5.546761\n",
      "loss: 6.639626\n",
      "loss: 5.919689\n",
      "loss: 6.240205\n",
      "loss: 5.655012\n",
      "loss: 5.146714\n",
      "loss: 6.359674\n",
      "loss: 4.718214\n",
      "loss: 5.690199\n",
      "loss: 6.092335\n",
      "loss: 6.985046\n",
      "loss: 6.593462\n",
      "loss: 5.550239\n",
      "loss: 5.886200\n",
      "loss: 6.709430\n",
      "loss: 5.436478\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10\n",
    "VALIDATION_SIZE = 5000  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5\n",
    "TEST_SIZE=55000\n",
    "TRAIN_SIZE=10000\n",
    "\n",
    "for step in xrange(NUM_EPOCHS * TRAIN_SIZE // BATCH_SIZE):\n",
    "    offset = (step * BATCH_SIZE) % (TRAIN_SIZE - BATCH_SIZE)\n",
    "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "    feed_dict = {\n",
    "        train_data_node: batch_data,\n",
    "        train_labels_node: batch_labels\n",
    "    }\n",
    "    # run training node and visualization node\n",
    "    status,result=tdb.debug([optimizer,p0], feed_dict=feed_dict, session=s)\n",
    "    if step % 10 == 0:        \n",
    "        status,result=tdb.debug([loss,p1,p2,p3,p4,ploss], feed_dict=feed_dict, session=s)\n",
    "        print('loss: %f' % (result[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
